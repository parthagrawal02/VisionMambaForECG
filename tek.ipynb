{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets_h5 import CustomDataset\n",
    "\n",
    "train_dataloader = CustomDataset(\"/Users/parthagrawal02/Desktop/Carelog/ECG_CNN/ecg_signal_merged.h5\")\n",
    "\n",
    "# # Iterate over the DataLoader\n",
    "# l = 0\n",
    "# for images, labels in train_dataloader:\n",
    "#     # Visualize the first image in the batch\n",
    "#     print(l+1)\n",
    "#     l = l + 1\n",
    "\n",
    "# print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(train_dataloader[90][0][3])\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "# import time\n",
    "# torch.cuda.synchronize()\n",
    "# start = time.time()\n",
    "# \"The process\"\n",
    "# torch.cuda.synchronize()\n",
    "# end = time.time()\n",
    "# print(\"name of process\", end-start)\n",
    "\n",
    "# plt.plot(np.array(list(epochs.values())[:][segment_idx]['Signal']))\n",
    "dict = {\n",
    "    1 : 0,\n",
    "    2: 0,\n",
    "    3: 0,\n",
    "    4: 0,\n",
    "    5: 0,\n",
    "    6: 0,\n",
    "    7: 0,\n",
    "    8: 0,\n",
    "    9: 0,\n",
    "    0: 0\n",
    "}\n",
    "count = 0\n",
    "for i in range(len(train_dataloader)):\n",
    "    # if torch.isnan(train_dataloader[i][0]).any():\n",
    "    dict[int(train_dataloader[i][1])] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "481199"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runtime of the program is 0.015565872192382812 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "train_dataloader[13][0]\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Total runtime of the program is {elapsed_time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (765188302.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    Total runtime of the program is 0.006891012191772461 seconds\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "Total runtime of the program is 0.006891012191772461 seconds\n",
    "Total runtime of the program is 0.004756927490234375 seconds\n",
    "Total runtime of the program is 0.0009140968322753906 seconds\n",
    "\n",
    "Total runtime of the program is 0.015565872192382812 seconds\n",
    "Total runtime of the program is 0.04595017433166504 seconds\n",
    "\n",
    "torch.isnan(train_dataloader[322][0][0]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(3,  4, figsize=(10,  10))  # Adjust figsize as needed\n",
    "data = train_dataloader[5807][0][0]\n",
    "# Plot each row of the array in a separate subplo\n",
    "axs = axs.flatten()\n",
    "for i in range(12):\n",
    "    axs[i].plot(data[i, :])\n",
    "    axs[i].set_title(f'Lead {i+1}')\n",
    "    axs[i].set_xlabel('Time')\n",
    "    axs[i].set_ylabel('Signal')\n",
    "# Adjust layout and spacing\n",
    "plt.tight_layout()\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def merge_datasets(input_file, output_file, output_dataset_name):\n",
    "    # Open the input HDF5 file in read mode\n",
    "    with h5py.File(input_file, 'r') as f:\n",
    "        # Get a list of dataset names\n",
    "        dataset_names = list(f.keys())\n",
    "        \n",
    "        # Determine the shape and dtype of the output dataset\n",
    "        output_shape = (sum(f[name].shape[0] for name in dataset_names),) + f[dataset_names[0]].shape[1:]\n",
    "        output_dtype = f[dataset_names[0]].dtype\n",
    "        \n",
    "        # Create the output HDF5 file\n",
    "        with h5py.File(output_file, 'w') as out_f:\n",
    "            # Create the output dataset\n",
    "            out_dataset = out_f.create_dataset(output_dataset_name, shape=output_shape, dtype=output_dtype)\n",
    "            \n",
    "            # Iterate over dataset names and concatenate data into the output dataset\n",
    "            start_idx = 0\n",
    "            for name in dataset_names:\n",
    "                dataset = f[name]\n",
    "                end_idx = start_idx + dataset.shape[0]\n",
    "                out_dataset[start_idx:end_idx, ...] = dataset[:]\n",
    "                start_idx = end_idx\n",
    "\n",
    "# Example usage\n",
    "input_file = 'input.h5'\n",
    "output_file = 'output.h5'\n",
    "output_dataset_name = 'merged_data'\n",
    "merge_datasets(input_file, output_file, output_dataset_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, label = train_dataloader[70800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import gzip\n",
    "import numpy as np\n",
    "\n",
    "# Path to your HDF5 file\n",
    "hdf5_file_path = '/Users/parthagrawal02/Desktop/Carelog/ECG_CNN/merged_dataset_ecg.h5'\n",
    "\n",
    "# Name of the gzip-compressed dataset inside the HDF5 file\n",
    "dataset_name = 'merged_dataset'\n",
    "\n",
    "# Open the HDF5 file in read/write mode\n",
    "with h5py.File(hdf5_file_path, 'r+') as hdf5_file:\n",
    "    # Check if the dataset exists in the HDF5 file\n",
    "    if dataset_name not in hdf5_file:\n",
    "        print(f\"Dataset '{dataset_name}' not found in the HDF5 file.\")\n",
    "    else:\n",
    "        # Read the compressed dataset from the HDF5 file\n",
    "        compressed_data = hdf5_file[dataset_name][()]\n",
    "\n",
    "        # Decompress the dataset\n",
    "        decompressed_data = gzip.decompress(compressed_data)\n",
    "\n",
    "        # Convert bytes to numpy array (if necessary)\n",
    "        # Adjust dtype and shape according to your data\n",
    "        decompressed_data_array = np.frombuffer(decompressed_data, dtype=np.uint8).reshape((-1,))\n",
    "\n",
    "        # Create a new uncompressed dataset in the HDF5 file\n",
    "        uncompressed_dataset_name = 'uncompressed_data'\n",
    "        hdf5_file.create_dataset(uncompressed_dataset_name, data=decompressed_data_array)\n",
    "\n",
    "        print(f\"Dataset '{dataset_name}' successfully decompressed and written to '{uncompressed_dataset_name}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "misc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
